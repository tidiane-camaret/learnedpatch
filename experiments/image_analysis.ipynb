{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visusalize images from the dataset.\n",
    "2. Visualize the behaviour of a random agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medsegbench import Promise12MSBench\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_dataset = Promise12MSBench(split=\"val\", transform=data_transform, target_transform=data_transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(len(val_dataset))\n",
    "image, gt = val_dataset[40]\n",
    "plt.imshow(image[0])\n",
    "plt.imshow(gt[0], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/work/dlclarge2/ndirt-SegFM3D/learnedpatch\") \n",
    "from src.patchselectionenv import GymPatchSelectionEnv, dice_score\n",
    "\n",
    "image_list = [val_dataset[i][0] for i in range(len(val_dataset))]\n",
    "mask_list = [val_dataset[i][1] for i in range(len(val_dataset))]\n",
    "patch_size = (64, 64)\n",
    "max_steps = 10\n",
    "\n",
    "env = GymPatchSelectionEnv(image_list, mask_list, patch_size, max_steps)\n",
    "\n",
    "# Train PPO agent\n",
    "#model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "done = False\n",
    "plt.imshow(obs[0].numpy())\n",
    "plt.show()\n",
    "while not done:\n",
    "    \n",
    "    #action, _ = model.predict(obs)\n",
    "    \n",
    "    r = np.random.randint(0, env.env.image.shape[0] - patch_size[0] + 1)\n",
    "    c = np.random.randint(0, env.env.image.shape[1] - patch_size[1] + 1)\n",
    "    action = (r, c)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    plt.imshow(obs[2].numpy(), alpha=0.5)\n",
    "    print(f\"Reward: {reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
